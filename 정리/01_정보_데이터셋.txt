●1. tf.data.Dataset
====================================================================================================
●1. tf.data.Dataset

1. Dataset 생성 함수
    1.1 from_tensor_slices
        역할: Python 리스트, 넘파이 배열, 텐서 등의 데이터로부터 Dataset을 생성합니다.
        ┌────────────────────────────────────────────────────┐
        import tensorflow as tf
        data = [1, 2, 3, 4, 5]
        dataset = tf.data.Dataset.from_tensor_slices(data)
        for item in dataset:
            print(item.numpy())
        └────────────────────────────────────────────────────┘


    1.2 from_generator
        역할: Python generator로부터 Dataset을 생성합니다.
        ┌──────────────────────────────────────────────────────────────────────────────┐
        def generator():
           for i in range(5):
               yield i * i

        dataset = tf.data.Dataset.from_generator(generator, output_types=tf.int32)
        for item in dataset:
         print(item.numpy())
        └──────────────────────────────────────────────────────────────────────────────┘


    1.3 range
        역할: 주어진 범위의 정수를 포함하는 Dataset을 생성합니다.
        ┌────────────────────────────────────────────────────┐
        dataset = tf.data.Dataset.range(5)
        for item in dataset:
            print(item.numpy())
        └────────────────────────────────────────────────────┘


    1.4 TFRecordDataset
        역할: TFRecord 파일로부터 데이터를 읽어 Dataset을 생성합니다.
        ┌────────────────────────────────────────────────────┐
        dataset = tf.data.TFRecordDataset(["data.tfrecord"])
        └────────────────────────────────────────────────────┘


    1.5 TextLineDataset
        역할: 텍스트 파일에서 각 줄을 읽어 Dataset을 생성합니다.
        ┌────────────────────────────────────────────────────┐
        dataset = tf.data.TextLineDataset("file.txt")
        └────────────────────────────────────────────────────┘

2. Dataset 변환 함수
    2.1 map
        역할: 데이터셋의 각 요소에 대해 주어진 함수를 적용합니다.
        ┌────────────────────────────────────────────────────┐
        dataset = tf.data.Dataset.range(5)
        dataset = dataset.map(lambda x: x * x)
        for item in dataset:
            print(item.numpy())
        └────────────────────────────────────────────────────┘

    2.2 filter
        역할: 조건을 만족하는 데이터만 남깁니다.

        ┌────────────────────────────────────────────────────┐
        dataset = tf.data.Dataset.range(10)
        dataset = dataset.filter(lambda x: x % 2 == 0)
        for item in dataset:
            print(item.numpy())
        └────────────────────────────────────────────────────┘
    2.3 batch
        역할: 데이터셋을 지정된 크기로 묶습니다.

        ┌────────────────────────────────────────────────────┐
        dataset = tf.data.Dataset.range(10)
        dataset = dataset.batch(3)
        for batch in dataset:
            print(batch.numpy())
        └────────────────────────────────────────────────────┘
    2.4 shuffle
        역할: 데이터를 무작위로 섞습니다.
        ┌────────────────────────────────────────────────────┐
        dataset = tf.data.Dataset.range(10)
        dataset = dataset.shuffle(buffer_size=5)
        for item in dataset:
            print(item.numpy())
        └────────────────────────────────────────────────────┘

    2.5 repeat
        역할: 데이터셋을 지정된 횟수만큼 반복합니다. 인수를 생략하면 무한 반복합니다.
        ┌────────────────────────────────────────────────────┐
        dataset = tf.data.Dataset.range(5).repeat(2)
        for item in dataset:
            print(item.numpy())
        └────────────────────────────────────────────────────┘

    2.6 prefetch
        역할: 데이터 로딩과 처리 병렬화를 위해 다음 데이터를 미리 로드합니다.
        ┌────────────────────────────────────────────────────────────────────────────┐
        dataset = tf.data.Dataset.range(10).prefetch(buffer_size=tf.data.AUTOTUNE)
        └────────────────────────────────────────────────────────────────────────────┘


3. Dataset 소비 함수
    3.1 take
        역할: 데이터셋의 첫 n개의 요소를 가져옵니다.
        ┌────────────────────────────────────────────────────┐
        dataset = tf.data.Dataset.range(10)
        for item in dataset.take(3):
            print(item.numpy())
        └────────────────────────────────────────────────────┘
    
    3.2 enumerate
        역할: 데이터셋의 각 요소에 인덱스를 추가합니다.
        ┌────────────────────────────────────────────────────┐
        dataset = tf.data.Dataset.range(3)
        dataset = dataset.enumerate(start=100)
        for index, value in dataset:
            print(f'Index: {index.numpy()}, Value: {value.numpy()}')
        └────────────────────────────────────────────────────┘
    

    3.3 as_numpy_iterator
        역할: Dataset을 numpy 형식으로 순회할 수 있는 iterator로 변환합니다.
        ┌────────────────────────────────────────────────────┐
        dataset = tf.data.Dataset.range(5)
        for item in dataset.as_numpy_iterator():
            print(item)
        └────────────────────────────────────────────────────┘
    

4. 고급 함수
    ★4.1 window
        역할: 데이터셋을 고정 크기의 윈도우로 나눕니다.
        ┌─────────────────────────────────────────────────────────────┐
        dataset = tf.data.Dataset.range(10)
        dataset = dataset.window(size=3, shift=1, drop_remainder=True)
        for window in dataset:
            print(list(window.as_numpy_iterator()))
        └─────────────────────────────────────────────────────────────┘
    
    4.2 flat_map
        역할: 데이터셋의 각 요소에 대해 새로운 데이터셋을 생성하고 이를 하나의 데이터셋으로 병합합니다.
        ┌────────────────────────────────────────────────────────────────┐
        dataset = tf.data.Dataset.range(3)
        dataset = dataset.flat_map(lambda x: tf.data.Dataset.range(x))
        for item in dataset:
            print(item.numpy())
        └────────────────────────────────────────────────────────────────┘
    
    4.3 interleave
        역할: 여러 데이터셋을 병렬로 혼합합니다.
        ┌───────────────────────────────────────────────────────────────────────────────┐
        dataset = tf.data.Dataset.range(3)
        dataset = dataset.interleave(lambda x: tf.data.Dataset.range(x), cycle_length=2)
        for item in dataset:
            print(item.numpy())
        └───────────────────────────────────────────────────────────────────────────────┘

    4.4 concatenate
        TensorFlow의 tf.data.Dataset을 사용할 때, 여러 데이터셋을 합칠 때는 concatenate() 함수를 사용할 수 있습니다.
        ┌──────────────────────────────────────────────────────────────────────┐
        import tensorflow as tf
        # 예시 데이터셋 1
        dataset1 = tf.data.Dataset.from_tensor_slices([1, 2, 3])
        # 예시 데이터셋 2
        dataset2 = tf.data.Dataset.from_tensor_slices([4, 5, 6])
        # 데이터셋 합치기
        combined_dataset = dataset1.concatenate(dataset2)
        # 출력
        for item in combined_dataset:
            print(item.numpy())
        └──────────────────────────────────────────────────────────────────────┘

5. 타겟값과 함께 데이터셋을 만들기
    ┌───────────────────────────────────────────────────────────────────────────────┐
    import tensorflow as tf

    # 예시 데이터
    data = [1, 2, 3, 4, 5]  # 특징값
    targets = [0, 1, 0, 1, 0]  # 타겟값

    # 데이터셋 생성
    dataset = tf.data.Dataset.from_tensor_slices((data, targets))

    # 데이터셋 사용
    for x, y in dataset:
        print(f'Feature: {x.numpy()}, Target: {y.numpy()}')
    └───────────────────────────────────────────────────────────────────────────────┘

6. 데이터셋 저장하고 불러오기
    (1) TFRecord로 데이터셋 저장하기
        ┌───────────────────────────────────────────────────────────────────────────────┐
        import tensorflow as tf
        # 예시 데이터셋
        data = [1, 2, 3, 4, 5]
        labels = [0, 1, 0, 1, 0]
        # 데이터셋 생성
        dataset = tf.data.Dataset.from_tensor_slices((data, labels))
        # TFRecord 저장을 위한 직렬화 함수
        def serialize_example(feature0, feature1):
            feature = {
                'feature0': tf.train.Feature(int64_list=tf.train.Int64List(value=[feature0])),
                'feature1': tf.train.Feature(int64_list=tf.train.Int64List(value=[feature1])),
            }
            example = tf.train.Example(features=tf.train.Features(feature=feature))
            return example.SerializeToString()

        # TFRecord 파일로 저장
        with tf.io.TFRecordWriter('dataset.tfrecord') as writer:
            for feature0, feature1 in dataset:
                example = serialize_example(feature0.numpy(), feature1.numpy())
                writer.write(example)
        └───────────────────────────────────────────────────────────────────────────────┘
    
    (2) TFRecord 파일에서 데이터셋 불러오기
        ┌───────────────────────────────────────────────────────────────────────────────┐
        import tensorflow as tf
        # TFRecord 파일에서 데이터셋 불러오기
        raw_dataset = tf.data.TFRecordDataset('dataset.tfrecord')
        # 파싱 함수 정의
        def _parse_function(proto):
            # 데이터셋에서 사용된 특성 정의
            keys_to_features = {
                'feature0': tf.io.FixedLenFeature([], tf.int64),
                'feature1': tf.io.FixedLenFeature([], tf.int64)
            }
            parsed_features = tf.io.parse_single_example(proto, keys_to_features)
            return parsed_features['feature0'], parsed_features['feature1']
    
        # 데이터셋 파싱
        dataset = raw_dataset.map(_parse_function)
        # 데이터셋 출력
        for item in dataset:
            print(item)
    
        └───────────────────────────────────────────────────────────────────────────────┘