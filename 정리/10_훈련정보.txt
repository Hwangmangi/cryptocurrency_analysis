#=======================================================================================================
batch = 256
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1hour30seq23feature2_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1hour30seq23feature2_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 23  # 한 샘플의 특성 수 (레이블 제외)

def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=4)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output1 + x)  # 잔차 연결
    x_ff1 = tf.keras.layers.Dense(128, activation='relu')(attn_output2)
    x_ff2 = tf.keras.layers.Dense(23, activation='relu')(x_ff1)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)

Epoch 1/100
    180656/180656 [==============================] - 3236s 18ms/step - loss: 0.5740 - accuracy: 0.7299 - val_loss: 0.5897 - val_accuracy: 0.7169
Epoch 2/100
    180656/180656 [==============================] - 3632s 20ms/step - loss: 0.5720 - accuracy: 0.7307 - val_loss: 0.5874 - val_accuracy: 0.7178
Epoch 3/100
    180656/180656 [==============================] - 3623s 20ms/step - loss: 0.5710 - accuracy: 0.7310 - val_loss: 0.5852 - val_accuracy: 0.7187
Epoch 4/100
    180656/180656 [==============================] - 3639s 20ms/step - loss: 0.5700 - accuracy: 0.7312 - val_loss: 0.5854 - val_accuracy: 0.7187
Epoch 5/100
    180656/180656 [==============================] - 3622s 20ms/step - loss: 0.5689 - accuracy: 0.7315 - val_loss: 0.5845 - val_accuracy: 0.7191
Epoch 6/100
    180656/180656 [==============================] - 3602s 20ms/step - loss: 0.5680 - accuracy: 0.7318 - val_loss: 0.5845 - val_accuracy: 0.7192
Epoch 7/100 
    157251/180656 [=========================>....] - ETA: 7:06 - loss: 0.5675 - accuracy: 0.7317


#=======================================================================================================
batch = 256
lr = 0.01
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'   -> Standardization
train_tfrecord_filename = '1hour30seq23feature2_TRAIN.tfrecord' 
val_tfrecord_filename = '1hour30seq23feature2_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 23  # 한 샘플의 특성 수 (레이블 제외)

def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=4)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output1 + x)  # 잔차 연결
    x_ff1 = tf.keras.layers.Dense(128, activation='relu')(attn_output2)
    x_ff2 = tf.keras.layers.Dense(23, activation='relu')(x_ff1)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)
None
Epoch 1/100
2024-12-22 09:48:08.760214: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2024-12-22 09:48:09.396344: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
134951/Unknown - 2158s 16ms/step - loss: 0.5809 - accuracy: 0.7269

#=======================================================================================================
batch = 256
lr = 0.002

output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1hour30seq23feature3_TRAIN.tfrecord'   -> min-max normalization
val_tfrecord_filename = '1hour30seq23feature3_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 23  # 한 샘플의 특성 수 (레이블 제외)

def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=4)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output1 + x)  # 잔차 연결
    x_ff1 = tf.keras.layers.Dense(128, activation='relu')(attn_output2)
    x_ff2 = tf.keras.layers.Dense(23, activation='relu')(x_ff1)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)

None
Epoch 1/100
2024-12-22 14:50:10.735470: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2024-12-22 14:50:12.333585: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
180656/180656 [==============================] - 2857s 16ms/step - loss: 0.5752 - accuracy: 0.7294 - val_loss: 0.5902 - val_accuracy: 0.7165
Epoch 2/100
180656/180656 [==============================] - 3279s 18ms/step - loss: 0.5743 - accuracy: 0.7296 - val_loss: 0.5892 - val_accuracy: 0.7170
Epoch 3/100
180656/180656 [==============================] - 3304s 18ms/step - loss: 0.5732 - accuracy: 0.7303 - val_loss: 0.5898 - val_accuracy: 0.7172
Epoch 4/100
180656/180656 [==============================] - 2708s 15ms/step - loss: 0.5727 - accuracy: 0.7305 - val_loss: 0.5879 - val_accuracy: 0.7181
Epoch 5/100
180656/180656 [==============================] - 3220s 18ms/step - loss: 0.5729 - accuracy: 0.7303 - val_loss: 0.5891 - val_accuracy: 0.7166
Epoch 6/100
1673/180656 [..............................] -


#=======================================================================================================
batch = 256
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1hour30seq23feature2_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1hour30seq23feature2_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 23  # 한 샘플의 특성 수 (레이블 제외)


def lstm_transformer_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x1 = tf.keras.layers.LSTM(23, return_sequences=True)(inputs)
    lstm_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x1)

    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=4)(lstm_out, lstm_out)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output1 + lstm_out)  # 잔차 연결

    x_ff1 = tf.keras.layers.Dense(128, activation='relu')(attn_output2)
    x_ff2 = tf.keras.layers.Dense(23, activation='relu')(x_ff1)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + lstm_out)  # 잔차 연결

    lstm_out2 = tf.keras.layers.LSTM(64)(dense_out)
    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out2)
    return tf.keras.models.Model(inputs, outputs)

    Model: "model"
    __________________________________________________________________________________________________
     Layer (type)                   Output Shape         Param #     Connected to
    ==================================================================================================
     input_1 (InputLayer)           [(None, 30, 23)]     0           []
    
     lstm (LSTM)                    (None, 30, 23)       4324        ['input_1[0][0]']
    
     layer_normalization (LayerNorm  (None, 30, 23)      46          ['lstm[0][0]']
     alization)
    
     multi_head_attention (MultiHea  (None, 30, 23)      24343       ['layer_normalization[0][0]',
     dAttention)                                                      'layer_normalization[0][0]']
    
     tf.__operators__.add (TFOpLamb  (None, 30, 23)      0           ['multi_head_attention[0][0]',
     da)                                                              'layer_normalization[0][0]']
    
     layer_normalization_1 (LayerNo  (None, 30, 23)      46          ['tf.__operators__.add[0][0]']
     rmalization)
    
     dense (Dense)                  (None, 30, 128)      3072        ['layer_normalization_1[0][0]']
    
     dense_1 (Dense)                (None, 30, 23)       2967        ['dense[0][0]']
    
     tf.__operators__.add_1 (TFOpLa  (None, 30, 23)      0           ['dense_1[0][0]',
     mbda)                                                            'multi_head_attention[0][0]']
    
     tf.__operators__.add_2 (TFOpLa  (None, 30, 23)      0           ['tf.__operators__.add_1[0][0]',
     mbda)                                                            'layer_normalization[0][0]']
    
     layer_normalization_2 (LayerNo  (None, 30, 23)      46          ['tf.__operators__.add_2[0][0]']
     rmalization)
    
     lstm_1 (LSTM)                  (None, 64)           22528       ['layer_normalization_2[0][0]']
    
     dense_2 (Dense)                (None, 1)            65          ['lstm_1[0][0]']
    
    ==================================================================================================
    Total params: 57,437
    Trainable params: 57,437
    Non-trainable params: 0
    __________________________________________________________________________________________________


    Epoch 1/100
    2024-12-22 19:51:57.197232: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
    2024-12-22 19:51:57.959689: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
    180656/180656 [==============================] - 2943s 16ms/step - loss: 0.5724 - accuracy: 0.7305 - val_loss: 0.5883 - val_accuracy: 0.7167
    Epoch 2/100
    180656/180656 [==============================] - 2947s 16ms/step - loss: 0.5706 - accuracy: 0.7312 - val_loss: 0.5885 - val_accuracy: 0.7175
    Epoch 3/100
    180656/180656 [==============================] - 2986s 17ms/step - loss: 0.5698 - accuracy: 0.7313 - val_loss: 0.5854 - val_accuracy: 0.7175
    Epoch 4/100
    2024-12-22 19:51:57.197232: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
    2024-12-22 19:51:57.959689: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
    180656/180656 [==============================] - 2943s 16ms/step - loss: 0.5724 - accuracy: 0.7305 - val_loss: 0.5883 - val_accuracy: 0.7167
    Epoch 2/100
    180656/180656 [==============================] - 2947s 16ms/step - loss: 0.5706 - accuracy: 0.7312 - val_loss: 0.5885 - val_accuracy: 0.7175
    Epoch 3/100
    180656/180656 [==============================] - 2986s 17ms/step - loss: 0.5698 - accuracy: 0.7313 - val_loss: 0.5854 - val_accuracy: 0.7175
    Epoch 4/100
    180656/180656 [==============================] - 2966s 16ms/step - loss: 0.5692 - accuracy: 0.7315 - val_loss: 0.5836 - val_accuracy: 0.7195
    2024-12-22 19:51:57.197232: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
    2024-12-22 19:51:57.959689: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
    180656/180656 [==============================] - 2943s 16ms/step - loss: 0.5724 - accuracy: 0.7305 - val_loss: 0.5883 - val_accuracy: 0.7167
    Epoch 2/100
    180656/180656 [==============================] - 2947s 16ms/step - loss: 0.5706 - accuracy: 0.7312 - val_loss: 0.5885 - val_accuracy: 0.7175
    Epoch 3/100
    180656/180656 [==============================] - 2986s 17ms/step - loss: 0.5698 - accuracy: 0.7313 - val_loss: 0.5854 - val_accuracy: 0.7175
    Epoch 4/100
    180656/180656 [==============================] - 2966s 16ms/step - loss: 0.5692 - accuracy: 0.7315 - val_loss: 0.5836 - val_accuracy: 0.7195
    Epoch 5/100
    180656/180656 [==============================] - 2915s 16ms/step - loss: 0.5687 - accuracy: 0.7316 - val_loss: 0.5838 - val_accuracy: 0.7192
    Epoch 6/100
    180656/180656 [==============================] - 2918s 16ms/step - loss: 0.5684 - accuracy: 0.7317 - val_loss: 0.5840 - val_accuracy: 0.7198
    Epoch 7/100
    180656/180656 [==============================] - 2919s 16ms/step - loss: 0.5682 - accuracy: 0.7318 - val_loss: 0.5853 - val_accuracy: 0.7184
    Epoch 8/100
    180656/180656 [==============================] - 2933s 16ms/step - loss: 0.5679 - accuracy: 0.7318 - val_loss: 0.5861 - val_accuracy: 0.7185
    Epoch 9/100
    180656/180656 [==============================] - 2931s 16ms/step - loss: 0.5677 - accuracy: 0.7319 - val_loss: 0.5832 - val_accuracy: 0.7195
    Epoch 10/100
    180656/180656 [==============================] - 2965s 16ms/step - loss: 0.5678 - accuracy: 0.7319 - val_loss: 0.5836 - val_accuracy: 0.7197
    Epoch 11/100
    180656/180656 [==============================] - 2969s 16ms/step - loss: 0.5673 - accuracy: 0.7320 - val_loss: 0.5844 - val_accuracy: 0.7191
    Epoch 12/100
    180656/180656 [==============================] - 2975s 16ms/step - loss: 0.5672 - accuracy: 0.7321 - val_loss: 0.5838 - val_accuracy: 0.7196
    Epoch 13/100
    180656/180656 [==============================] - 2898s 16ms/step - loss: 0.5690 - accuracy: 0.7317 - val_loss: 0.5975 - val_accuracy: 0.7075
    Epoch 14/100
    180656/180656 [==============================] - 2915s 16ms/step - loss: 0.5717 - accuracy: 0.7310 - val_loss: 0.5994 - val_accuracy: 0.7073


#=======================================================================================================
batch = 256
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1hour30seq23feature2_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1hour30seq23feature2_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 23  # 한 샘플의 특성 수 (레이블 제외)

def transformer_lstm_model(input_shape):  잔차연결 제외
    inputs = tf.keras.layers.Input(shape=input_shape)

    # Transformer 인코더 블록
    # x = transformer_encoder(inputs)
    x = PositionEncoding()(inputs)

    # Transformer 인코더 블록
    # attn_output = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=4, dropout=0.1)(x, x)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=4)(x, x)
    # attn_output = tf.keras.layers.Dropout(0.3)(attn_output)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output1)  # 잔차 연결

    # 포인트 와이즈 피드포워드 네트워크
    x_ff1 = tf.keras.layers.Dense(128, activation='relu')(attn_output2)
    x_ff2 = tf.keras.layers.Dense(23, activation='relu')(x_ff1)
    # x_ff = tf.keras.layers.Dropout(0.3)(x_ff)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2)  # 잔차 연결

    # LSTM 계층
    lstm_out = tf.keras.layers.LSTM(64)(dense_out)

    # 출력 계층
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)
    __________________________________________________________________________________________________
    Layer (type)                   Output Shape         Param #     Connected to
   ==================================================================================================
    input_1 (InputLayer)           [(None, 30, 23)]     0           []
   
    position_encoding (PositionEnc  (None, 30, 23)      0           ['input_1[0][0]']
    oding)
   
    multi_head_attention (MultiHea  (None, 30, 23)      24343       ['position_encoding[0][0]',
    dAttention)                                                      'position_encoding[0][0]']
   
    layer_normalization (LayerNorm  (None, 30, 23)      46          ['multi_head_attention[0][0]']
    alization)
   
    dense (Dense)                  (None, 30, 128)      3072        ['layer_normalization[0][0]']
   
    dense_1 (Dense)                (None, 30, 23)       2967        ['dense[0][0]']
   
    layer_normalization_1 (LayerNo  (None, 30, 23)      46          ['dense_1[0][0]']
    rmalization)
   
    lstm (LSTM)                    (None, 64)           22528       ['layer_normalization_1[0][0]']
   
    dense_2 (Dense)                (None, 1)            65          ['lstm[0][0]']
   
   ==================================================================================================
   Total params: 53,067


   None
   Epoch 1/100
   2024-12-23 10:39:52.686899: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
   2024-12-23 10:39:54.506554: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
   180656/180656 [==============================] - 3484s 19ms/step - loss: 0.5750 - accuracy: 0.7293 - val_loss: 0.5939 - val_accuracy: 0.7115
   Epoch 4/100
   180656/180656 [==============================] - 2525s 14ms/step - loss: 0.5727 - accuracy: 0.7306 - val_loss: 0.5883 - val_accuracy: 0.7166
   Epoch 5/100
   180656/180656 [==============================] - 2532s 14ms/step - loss: 0.5724 - accuracy: 0.7307 - val_loss: 0.5869 - val_accuracy: 0.7181
   Epoch 6/100
   180656/180656 [==============================] - 2508s 14ms/step - loss: 0.5722 - accuracy: 0.7308 - val_loss: 0.5868 - val_accuracy: 0.7183
   Epoch 7/100
   180656/180656 [==============================] - 2523s 14ms/step - loss: 0.5723 - accuracy: 0.7307 - val_loss: 0.5861 - val_accuracy: 0.7189
   Epoch 8/100
   180655/180656 [============================>.] - ETA: 0s - loss: 0.5720 - accuracy: 0.7309  















































#=======================================================================================================
batch = 256
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1hour30seq23feature2_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1hour30seq23feature2_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 23  # 한 샘플의 특성 수 (레이블 제외)

   def transformer_lstm_model(input_shape):
   inputs = tf.keras.layers.Input(shape=input_shape)
   x = PositionEncoding()(inputs)
   attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=4)(x, x)
   attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output1 + x)  # 잔차 연결
   x_ff1 = tf.keras.layers.Dense(128, activation='tanh')(attn_output2)
   x_ff2 = tf.keras.layers.Dense(23, activation='tanh')(x_ff1)
   dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
   lstm_out = tf.keras.layers.LSTM(64)(dense_out)
   output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

   return tf.keras.models.Model(inputs, output)
   Epoch 1/100
   2024-12-24 02:24:59.745654: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
   2024-12-24 02:25:01.333506: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
   180656/180656 [==============================] - 2466s 14ms/step - loss: 0.5739 - accuracy: 0.7299 - val_loss: 0.5882 - val_accuracy: 0.7179
   Epoch 2/100
   180656/180656 [==============================] - 2439s 13ms/step - loss: 0.5717 - accuracy: 0.7307 - val_loss: 0.5879 - val_accuracy: 0.7184
   Epoch 3/100
   180656/180656 [==============================] - 2476s 14ms/step - loss: 0.5704 - accuracy: 0.7310 - val_loss: 0.5853 - val_accuracy: 0.7185
   Epoch 4/100
   180656/180656 [==============================] - 2459s 14ms/step - loss: 0.5692 - accuracy: 0.7313 - val_loss: 0.5844 - val_accuracy: 0.7197
   Epoch 5/100
   180656/180656 [==============================] - 2469s 14ms/step - loss: 0.5679 - accuracy: 0.7317 - val_loss: 0.5832 - val_accuracy: 0.7199
   Epoch 6/100
   180656/180656 [==============================] - 2470s 14ms/step - loss: 0.5668 - accuracy: 0.7321 - val_loss: 0.5837 - val_accuracy: 0.7202
   Epoch 7/100
   180656/180656 [==============================] - 2473s 14ms/step - loss: 0.5657 - accuracy: 0.7325 - val_loss: 0.5831 - val_accuracy: 0.7202
   Epoch 8/100
   180656/180656 [==============================] - 2475s 14ms/step - loss: 0.5649 - accuracy: 0.7328 - val_loss: 0.5831 - val_accuracy: 0.7203
   Epoch 9/100
   180656/180656 [==============================] - 2469s 14ms/step - loss: 0.5642 - accuracy: 0.7330 - val_loss: 0.5823 - val_accuracy: 0.7205
   Epoch 10/100
   180656/180656 [==============================] - 2481s 14ms/step - loss  : 0.5636 - accuracy: 0.7332 - val_loss: 0.5816 - val_accuracy: 0.7205
   Epoch 11/100
   180656/180656 [==============================] - 2492s 14ms/step - loss: 0.5630 - accuracy: 0.7335 - val_loss: 0.5819 - val_accuracy: 0.7204


#=======================================================================================================
batch = 256
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1hour30seq23feature2_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1hour30seq23feature2_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 23  # 한 샘플의 특성 수 (레이블 제외)

def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=4)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output1 + x)  # 잔차 연결
    x_ff1 = tf.keras.layers.Dense(46, activation='tanh')(attn_output2)
    x_ff2 = tf.keras.layers.Dense(23, activation='tanh')(x_ff1)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)
    Epoch 1/100
    2024-12-24 11:55:36.311222: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
    2024-12-24 11:55:37.011434: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
    180656/180656 [==============================] - 3388s 19ms/step - loss: 0.5739 - accuracy: 0.7299 - val_loss: 0.5889 - val_accuracy: 0.7162
    Epoch 2/100
    180656/180656 [==============================] - 2924s 16ms/step - loss: 0.5719 - accuracy: 0.7307 - val_loss: 0.5878 - val_accuracy: 0.7178
    Epoch 3/100
    114156/180656 [=================>............] - ETA: 18:55 - loss: 0.5705 - accuracy: 0.7308

#=======================================================================================================
batch = 256
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1hour30seq23feature2_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1hour30seq23feature2_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 23  # 한 샘플의 특성 수 (레이블 제외)

    def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=4)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output1 + x)  # 잔차 연결
    x_ff2 = tf.keras.layers.Dense(23, activation='tanh')(attn_output1)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)
    callback path: C:\code\python\autohunting\model\{model_checkpoint2.h5}
    Epoch 1/100
    2024-12-24 15:40:16.640273: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.        _________
    2024-12-24 15:40:18.079108: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
    180656/180656 [==============================] - 2672s 15ms/step - loss: 0.5740 - accuracy: 0.7299 - val_loss: 0.5874 - val_accuracy: 0.7174                                      oat-32 will be used for the matrix multiplication. This will only be logged once.
    Epoch 2/100                                                                              NN version 8101
    180656/180656 [==============================] - 3086s 17ms/step - loss: 0.5720 - accuracy: 0.7299 - val_loss: 0.5874 - val_accuracy: 0.7174y: 0.7307 - val_loss: 0.5850 - val_accuracy: 0.7193
    Epoch 3/100                                                                              NN version 8101
    180656/180656 [==============================] - 2812s 16ms/step - loss: 0.5708 - accuracy: 0.7310 - val_loss: 0.5845 - val_accuracy: 0.7197

    None
    Epoch 1/100
    2024-12-25 21:21:50.649916: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
    2024-12-25 21:21:51.333895: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
    180656/180656 [==============================] - 2501s 14ms/step - loss: 0.5627 - accuracy: 0.7336 - val_loss: 0.5821 - val_accuracy: 0.7202
    Epoch 2/100
    180656/180656 [==============================] - 2427s 13ms/step - loss: 0.5623 - accuracy: 0.7338 - val_loss: 0.5824 - val_accuracy: 0.7198
    Epoch 3/100
    180656/180656 [==============================] - 2352s 13ms/step - loss: 0.5619 - accuracy: 0.7339 - val_loss: 0.5834 - val_accuracy: 0.7200
    Epoch 4/100
    180656/180656 [==============================] - 2333s 13ms/step - loss: 0.5615 - accuracy: 0.7341 - val_loss: 0.5827 - val_accuracy: 0.7196
    Epoch 5/100
    180656/180656 [==============================] - 2342s 13ms/step - loss: 0.5615 - accuracy: 0.7341 - val_loss: 0.5819 - val_accuracy: 0.7202
    Epoch 6/100
    180656/180656 [==============================] - 2339s 13ms/step - loss: 0.5612 - accuracy: 0.7342 - val_loss: 0.5816 - val_accuracy: 0.7198
    Epoch 7/100
    180656/180656 [==============================] - 2337s 13ms/step - loss: 0.5770 - accuracy: 0.7289 - val_loss: 0.6057 - val_accuracy: 0.7073
    Epoch 8/100
    180656/180656 [==============================] - 2347s 13ms/step - loss: 0.5849 - accuracy: 0.7250 - val_loss: 0.6055 - val_accuracy: 0.7073
    Epoch 9/100
    180656/180656 [==============================] - 2350s 13ms/step - loss: 0.5855 - accuracy: 0.7245 - val_loss: 0.6051 - val_accuracy: 0.7073
    Epoch 10/100
    180656/180656 [==============================] - 2379s 13ms/step - loss: 0.5854 - accuracy: 0.7245 - val_loss: 0.6047 - val_accuracy: 0.7073
    Epoch 11/100
    180656/180656 [==============================] - 2331s 13ms/step - loss: 0.5852 - accuracy: 0.7246 - val_loss: 0.6045 - val_accuracy: 0.7073
    Epoch 12/100
    180656/180656 [==============================] - 2328s 13ms/step - loss: 0.5845 - accuracy: 0.7247 - val_loss: 0.6037 - val_accuracy: 0.7073
    Epoch 13/100
    180656/180656 [==============================] - ETA: 0s - loss: 0.5806 - accuracy: 0.7271Traceback (most recent call last):
#=======================================================================================================
batch = 256
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1hour30seq23feature2_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1hour30seq23feature2_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 23  # 한 샘플의 특성 수 (레이블 제외)

def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=4)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output1 + x)  # 잔차 연결
    # x_ff1 = tf.keras.layers.Dense(46, activation='tanh')(attn_output2) 
    x_ff2 = tf.keras.layers.Dense(23, activation='tanh')(attn_output2)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    # lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    lstm_out = tf.keras.layers.GlobalMaxPooling1D()(dense_out)  # 시퀀스 차원을 축소
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)


    callback path: C:\code\python\autohunting\model\{model_checkpoint3.h5}
    Epoch 1/100
    2024-12-24 18:11:33.229346: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
    180656/180656 [==============================] - 2182s 12ms/step - loss: 0.5750 - accuracy: 0.7294 - val_loss: 0.5919 - val_accuracy: 0.7121
    Epoch 2/100
    180656/180656 [==============================] - 2820s 16ms/step - loss: 0.5735 - accuracy: 0.7302 - val_loss: 0.5875 - val_accuracy: 0.7177
    Epoch 3/100
    180656/180656 [==============================] - 2377s 13ms/step - loss: 0.5730 - accuracy: 0.7304 - val_loss: 0.5877 - val_accuracy: 0.7174
    Epoch 4/100
    113671/180656 [=================>............] - ETA: 15:34 - loss: 0.5723 - accuracy: 0.7303  


#=======================================================================================================
batch = 256
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1hour30seq23feature2_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1hour30seq23feature2_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 23  # 한 샘플의 특성 수 (레이블 제외)

model_checkpoint2
    None
    Epoch 1/100
    2024-12-24 21:00:02.308963: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
    2024-12-24 21:00:02.919754: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
    180656/180656 [==============================] - 2754s 15ms/step - loss: 0.5699 - accuracy: 0.7312 - val_loss: 0.5832 - val_accuracy: 0.7200
    Epoch 2/100
    180656/180656 [==============================] - 2388s 13ms/step - loss: 0.5687 - accuracy: 0.7315 - val_loss: 0.5845 - val_accuracy: 0.7196
    Epoch 3/100
    180656/180656 [==============================] - 2380s 13ms/step - loss: 0.5676 - accuracy: 0.7318 - val_loss: 0.5828 - val_accuracy: 0.7201
    Epoch 4/100
    180656/180656 [==============================] - 2358s 13ms/step - loss: 0.5667 - accuracy: 0.7322 - val_loss: 0.5827 - val_accuracy: 0.7198
    Epoch 5/100
    180656/180656 [==============================] - 2353s 13ms/step - loss: 0.5659 - accuracy: 0.7325 - val_loss: 0.5826 - val_accuracy: 0.7198
    Epoch 6/100
    180656/180656 [==============================] - 2330s 13ms/step - loss: 0.5651 - accuracy: 0.7327 - val_loss: 0.5829 - val_accuracy: 0.7199
    Epoch 7/100
    180656/180656 [==============================] - 2344s 13ms/step - loss: 0.5644 - accuracy: 0.7330 - val_loss: 0.5823 - val_accuracy: 0.7200
    Epoch 8/100
    180656/180656 [==============================] - 2316s 13ms/step - loss: 0.5639 - accuracy: 0.7332 - val_loss: 0.5822 - val_accuracy: 0.7200
    Epoch 9/100
    180656/180656 [==============================] - 2347s 13ms/step - loss: 0.5633 - accuracy: 0.7334 - val_loss: 0.5818 - val_accuracy: 0.7200
    Epoch 10/100
    180656/180656 [==============================] - 2320s 13ms/step - loss: 0.5657 - accuracy: 0.7326 - val_loss: 0.5805 - val_accuracy: 0.7203
    Epoch 11/100
    180656/180656 [==============================] - 2350s 13ms/step - loss: 0.5628 - accuracy: 0.7336 - val_loss: 0.5827 - val_accuracy: 0.7198
    Epoch 12/100
    180656/180656 [==============================] - 2306s 13ms/step - loss: 0.5622 - accuracy: 0.7338 - val_loss: 0.5831 - val_accuracy: 0.7188
    Epoch 13/100
    180656/180656 [==============================] - 2328s 13ms/step - loss: 0.5619 - accuracy: 0.7339 - val_loss: 0.5824 - val_accuracy: 0.7197
    Epoch 14/100
    180656/180656 [==============================] - 2312s 13ms/step - loss: 0.5615 - accuracy: 0.7341 - val_loss: 0.5828 - val_accuracy: 0.7193
    Epoch 15/100
    180656/180656 [==============================] - 2336s 13ms/step - loss: 0.5619 - accuracy: 0.7339 - val_loss: 0.5832 - val_accuracy: 0.7189
    PS C:\code> 



#=======================================================================================================
batch = 256
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1hour30seq23feature2_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1hour30seq23feature2_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 23  # 한 샘플의 특성 수 (레이블 제외)
def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=4)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output1 + x)  # 잔차 연결
    x_ff1 = tf.keras.layers.Dense(92, activation='tanh')(attn_output2) 
    x_ff2 = tf.keras.layers.Dense(46, activation='tanh')(x_ff1) 
    x_ff3 = tf.keras.layers.Dense(23, activation='tanh')(x_ff2)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff3 + attn_output1 + x)  # 잔차 연결
    l1 = tf.keras.layers.LSTM(92,return_sequences=True)(dense_out)
    l2 = tf.keras.layers.LSTM(46,return_sequences=True)(l1)
    lstm_out = tf.keras.layers.LSTM(23)(l2)
    # lstm_out = tf.keras.layers.GlobalMaxPooling1D()(dense_out)  # 시퀀스 차원을 축소
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)


    callback path: C:\code\python\autohunting\model\model_checkpoint5.h5
    Epoch 1/100
    2024-12-25 10:41:45.143006: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
    2024-12-25 10:41:45.835488: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
    180656/180656 [==============================] - 3633s 20ms/step - loss: 0.5744 - accuracy: 0.7297 - val_loss: 0.5914 - val_accuracy: 0.7137
    Epoch 2/100
     55820/180656 [========>.....................] - ETA: 38:15 - loss: 0.5759 

#=======================================================================================================
batch = 256
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1hour30seq23feature2_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1hour30seq23feature2_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 23  # 한 샘플의 특성 수 (레이블 제외)


def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=8)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output1 + x)  # 잔차 연결
    # x_ff1 = tf.keras.layers.Dense(46, activation='tanh')(attn_output2) 
    x_ff2 = tf.keras.layers.Dense(23, activation='tanh')(attn_output2)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    lstm_out = tf.keras.layers.LSTM(32 )(dense_out)
    # lstm_out = tf.keras.layers.GlobalMaxPooling1D()(dense_out)  # 시퀀스 차원을 축소
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)
    callback path: C:\code\python\autohunting\model\model_checkpoint6.h5
    Epoch 1/100
    2024-12-25 12:06:25.956697: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
    2024-12-25 12:06:26.580850: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
    180656/180656 [==============================] - 2285s 13ms/step - loss: 0.5739 - accuracy: 0.7299 - val_loss: 0.5884 - val_accuracy: 0.7177
    Epoch 2/100
    180656/180656 [==============================] - 2145s 12ms/step - loss: 0.5719 - accuracy: 0.7307 - val_loss: 0.5866 - val_accuracy: 0.7187
    Epoch 3/100
    180656/180656 [==============================] - 2157s 12ms/step - loss: 0.5709 - accuracy: 0.7310 - val_loss: 0.5866 - val_accuracy: 0.7187
    Epoch 4/100
    180656/180656 [==============================] - 2176s 12ms/step - loss: 0.5701 - accuracy: 0.7312 - val_loss: 0.5855 - val_accuracy: 0.7193
    Epoch 5/100
    180656/180656 [==============================] - 2164s 12ms/step - loss: 0.5694 - accuracy: 0.7314 - val_loss: 0.5866 - val_accuracy: 0.7180
    Epoch 6/100
    180656/180656 [==============================] - 2155s 12ms/step - loss: 0.5689 - accuracy: 0.7315 - val_loss: 0.5843 - val_accuracy: 0.7200
    Epoch 7/100
    180656/180656 [==============================] - 2166s 12ms/step - loss: 0.5685 - accuracy: 0.7316 - val_loss: 0.5838 - val_accuracy: 0.7200
    Epoch 8/100
    180656/180656 [==============================] - 2117s 12ms/step - loss: 0.5682 - accuracy: 0.7317 - val_loss: 0.5824 - val_accuracy: 0.7202
    Epoch 9/100
    128463/180656 [====================>.........] - ETA: 9:24 - loss: 0.5676 - accuracy: 0.7317 


#=======================================================================================================
batch = 256
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1hour30seq23feature2_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1hour30seq23feature2_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 23  # 한 샘플의 특성 수 (레이블 제외)

def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=8)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-8)(attn_output1 + x)  # 잔차 연결
    x_ff1 = tf.keras.layers.Dense(128, activation='tanh')(attn_output2) 
    x_ff2 = tf.keras.layers.Dense(23, activation='tanh')(x_ff1) 
    # x_ff3 = tf.keras.layers.Dense(23, activation='tanh')(x_ff2)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    # lstm_out = tf.keras.layers.GlobalMaxPooling1D()(dense_out)  # 시퀀스 차원을 축소
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)


    Model: "model"
    __________________________________________________________________________________________________
     Layer (type)                   Output Shape         Param #     Connected to
    ==================================================================================================
     input_1 (InputLayer)           [(None, 30, 23)]     0           []
    
     position_encoding (PositionEnc  (None, 30, 23)      0           ['input_1[0][0]']
     oding)
    
     multi_head_attention (MultiHea  (None, 30, 23)      48663       ['position_encoding[0][0]',
     dAttention)                                                      'position_encoding[0][0]']
    
     tf.__operators__.add (TFOpLamb  (None, 30, 23)      0           ['multi_head_attention[0][0]',
     da)                                                              'position_encoding[0][0]']
    
     layer_normalization (LayerNorm  (None, 30, 23)      46          ['tf.__operators__.add[0][0]']
     alization)
    
     dense (Dense)                  (None, 30, 128)      3072        ['layer_normalization[0][0]']
    
     dense_1 (Dense)                (None, 30, 23)       2967        ['dense[0][0]']
    
     tf.__operators__.add_1 (TFOpLa  (None, 30, 23)      0           ['dense_1[0][0]',
     mbda)                                                            'multi_head_attention[0][0]']
    
     tf.__operators__.add_2 (TFOpLa  (None, 30, 23)      0           ['tf.__operators__.add_1[0][0]',
     mbda)                                                            'position_encoding[0][0]']
    
     layer_normalization_1 (LayerNo  (None, 30, 23)      46          ['tf.__operators__.add_2[0][0]']
     rmalization)
    
     lstm (LSTM)                    (None, 64)           22528       ['layer_normalization_1[0][0]']
    
     dense_2 (Dense)                (None, 1)            65          ['lstm[0][0]']
    
    ==================================================================================================
    Total params: 77,387
    Trainable params: 77,387
    Non-trainable params: 0
    __________________________________________________________________________________________________
    None
    callback path: C:\code\python\autohunting\model\model_checkpoint8.h5

    Epoch 2/100
    180656/180656 [==============================] - 3105s 17ms/step - loss: 0.5665 - accuracy: 0.7323 - val_loss: 0.5852 - val_accuracy: 0.7198
    Epoch 3/100
    180656/180656 [==============================] - 3099s 17ms/step - loss: 0.5658 - accuracy: 0.7326 - val_loss: 0.5839 - val_accuracy: 0.7200
    Epoch 4/100
    180656/180656 [==============================] - 3098s 17ms/step - loss: 0.5651 - accuracy: 0.7329 - val_loss: 0.5842 - val_accuracy: 0.7202
    Epoch 5/100
    180656/180656 [==============================] - 3101s 17ms/step - loss: 0.5646 - accuracy: 0.7331 - val_loss: 0.5839 - val_accuracy: 0.7199
    Epoch 6/100
    180656/180656 [==============================] - 3104s 17ms/step - loss: 0.5640 - accuracy: 0.7332 - val_loss: 0.5825 - val_accuracy: 0.7207
    Epoch 7/100
    180656/180656 [==============================] - 3112s 17ms/step - loss: 0.5652 - accuracy: 0.7328 - val_loss: 0.5832 - val_accuracy: 0.7202
    Epoch 8/100
    180656/180656 [==============================] - 3109s 17ms/step - loss: 0.5631 - accuracy: 0.7336 - val_loss: 0.5827 - val_accuracy: 0.7205
    Epoch 9/100
    180656/180656 [==============================] - 3102s 17ms/step - loss: 0.5627 - accuracy: 0.7337 - val_loss: 0.5811 - val_accuracy: 0.7208
    Epoch 10/100
    180656/180656 [==============================] - 3101s 17ms/step - loss: 0.5624 - accuracy: 0.7338 - val_loss: 0.5815 - val_accuracy: 0.7205
    180656/180656 [==============================] - 3905s 22ms/step - loss: 0.5613 - accuracy: 0.7343 - val_loss: 0.5850 - val_accuracy: 0.7193
    Epoch 14/100
    180656/180656 [==============================] - 3254s 18ms/step - loss: 0.5610 - accuracy: 0.7344 - val_loss: 0.5804 - val_accuracy: 0.7207
    Epoch 15/100
    180656/180656 [==============================] - 3162s 18ms/step - loss: 0.5632 - accuracy: 0.7336 - val_loss: 0.5797 - val_accuracy: 0.7208
    Epoch 16/100
    180656/180656 [==============================] - 3102s 17ms/step - loss: 0.5605 - accuracy: 0.7346 - val_loss: 0.5786 - val_accuracy: 0.7211
    Epoch 17/100
    180656/180656 [==============================] - 3097s 17ms/step - loss: 0.5606 - accuracy: 0.7345 - val_loss: 0.5805 - val_accuracy: 0.7205
    Epoch 18/100
    180656/180656 [==============================] - 3114s 17ms/step - loss: 0.5601 - accuracy: 0.7347 - val_loss: 0.5816 - val_accuracy: 0.7201
    Epoch 19/100
    180656/180656 [==============================] - 3245s 18ms/step - loss: 0.5689 - accuracy: 0.7319 - val_loss: 0.6026 - val_accuracy: 0.7073
    Epoch 20/100

#=======================================================================================================
batch = 128
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1day30seq38feature_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1day30seq38feature_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 23  # 한 샘플의 특성 수 (레이블 제외)

def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=8)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-8)(attn_output1 + x)  # 잔차 연결
    x_ff1 = tf.keras.layers.Dense(128, activation='tanh')(attn_output2) 
    x_ff2 = tf.keras.layers.Dense(23, activation='tanh')(x_ff1) 
    # x_ff3 = tf.keras.layers.Dense(23, activation='tanh')(x_ff2)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    # lstm_out = tf.keras.layers.GlobalMaxPooling1D()(dense_out)  # 시퀀스 차원을 축소
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)

    Model: "model"
    __________________________________________________________________________________________________
     Layer (type)                   Output Shape         Param #     Connected to
    ==================================================================================================
     input_1 (InputLayer)           [(None, 30, 23)]     0           []
    
     position_encoding (PositionEnc  (None, 30, 23)      0           ['input_1[0][0]']
     oding)
    
     multi_head_attention (MultiHea  (None, 30, 23)      48663       ['position_encoding[0][0]',
     dAttention)                                                      'position_encoding[0][0]']
    
     tf.__operators__.add (TFOpLamb  (None, 30, 23)      0           ['multi_head_attention[0][0]',
     da)                                                              'position_encoding[0][0]']
    
     layer_normalization (LayerNorm  (None, 30, 23)      46          ['tf.__operators__.add[0][0]']
     alization)
    
     dense (Dense)                  (None, 30, 128)      3072        ['layer_normalization[0][0]']
    
     dense_1 (Dense)                (None, 30, 23)       2967        ['dense[0][0]']
    
     tf.__operators__.add_1 (TFOpLa  (None, 30, 23)      0           ['dense_1[0][0]',
     mbda)                                                            'multi_head_attention[0][0]']
    
     tf.__operators__.add_2 (TFOpLa  (None, 30, 23)      0           ['tf.__operators__.add_1[0][0]',
     mbda)                                                            'position_encoding[0][0]']
    
     layer_normalization_1 (LayerNo  (None, 30, 23)      46          ['tf.__operators__.add_2[0][0]']
     rmalization)
    
     lstm (LSTM)                    (None, 64)           22528       ['layer_normalization_1[0][0]']
    
     dense_2 (Dense)                (None, 1)            65          ['lstm[0][0]']
    
    ==================================================================================================
    Total params: 77,387
    Trainable params: 77,387
    Non-trainable params: 0
    __________________________________________________________________________________________________
    None
    callback path: C:\code\python\autohunting\model\model_checkpoin9.h5

    12271/12271 [==============================] - 185s 15ms/step - loss: 0.5812 - accuracy: 0.7200 - val_loss: 0.6213 - val_accuracy: 0.7177
    Epoch 5/100
    12271/12271 [==============================] - 183s 15ms/step - loss: 0.5781 - accuracy: 0.7211 - val_loss: 0.6239 - val_accuracy: 0.7148
    Epoch 6/100
    12271/12271 [==============================] - 185s 15ms/step - loss: 0.5750 - accuracy: 0.7222 - val_loss: 0.6240 - val_accuracy: 0.7151
    Epoch 7/100
    12271/12271 [==============================] - 180s 15ms/step - loss: 0.5724 - accuracy: 0.7232 - val_loss: 0.6232 - val_accuracy: 0.7186
    Epoch 8/100
    12271/12271 [==============================] - 259s 21ms/step - loss: 0.5696 - accuracy: 0.7244 - val_loss: 0.6324 - val_accuracy: 0.7150
    Epoch 9/100
    12271/12271 [==============================] - 323s 26ms/step - loss: 0.5673 - accuracy: 0.7253 - val_loss: 0.6262 - val_accuracy: 0.7153
    Epoch 10/100
    12271/12271 [==============================] - 280s 23ms/step - loss: 0.5649 - accuracy: 0.7263 - val_loss: 0.6273 - val_accuracy: 0.7167
    Epoch 11/100
    12271/12271 [==============================] - 195s 16ms/step - loss: 0.5628 - accuracy: 0.7273 - val_loss: 0.6412 - val_accuracy: 0.7184
    PS C:\code>
    

#=======================================================================================================
batch = 128
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1day30seq38feature_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1day30seq38feature_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 38  # 한 샘플의 특성 수 (레이블 제외)

def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=8)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-8)(attn_output1 + x)  # 잔차 연결
    x_ff1 = tf.keras.layers.Dense(128, activation='tanh')(attn_output2) 
    x_ff2 = tf.keras.layers.Dense(38, activation='tanh')(x_ff1) 
    # x_ff3 = tf.keras.layers.Dense(23, activation='tanh')(x_ff2)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    # lstm_out = tf.keras.layers.GlobalMaxPooling1D()(dense_out)  # 시퀀스 차원을 축소
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)

    callback path: C:\code\python\autohunting\model\model_checkpoin10.h5
Epoch 1/100
2025-01-05 17:34:05.045505: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2025-01-05 17:34:06.546489: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
12271/12271 [==============================] - 197s 16ms/step - loss: 0.5907 - accuracy: 0.7176 - val_loss: 0.6198 - val_accuracy: 0.7185
Epoch 2/100
12271/12271 [==============================] - 190s 16ms/step - loss: 0.5868 - accuracy: 0.7181 - val_loss: 0.6127 - val_accuracy: 0.7181
Epoch 3/100
12271/12271 [==============================] - 186s 15ms/step - loss: 0.5841 - accuracy: 0.7189 - val_loss: 0.6260 - val_accuracy: 0.7180
Epoch 4/100
12271/12271 [==============================] - 185s 15ms/step - loss: 0.5815 - accuracy: 0.7198 - val_loss: 0.6135 - val_accuracy: 0.7168
Epoch 5/100
12271/12271 [==============================] - 198s 16ms/step - loss: 0.5791 - accuracy: 0.7208 - val_loss: 0.6092 - val_accuracy: 0.7153
Epoch 6/100
12271/12271 [==============================] - 236s 19ms/step - loss: 0.5761 - accuracy: 0.7220 - val_loss: 0.6267 - val_accuracy: 0.7202
Epoch 7/100
12271/12271 [==============================] - 243s 20ms/step - loss: 0.5734 - accuracy: 0.7228 - val_loss: 0.6288 - val_accuracy: 0.7190
Epoch 8/100
12271/12271 [==============================] - 255s 21ms/step - loss: 0.5713 - accuracy: 0.7238 - val_loss: 0.6240 - val_accuracy: 0.7191
Epoch 9/100
12271/12271 [==============================] - 246s 20ms/step - loss: 0.5690 - accuracy: 0.7248 - val_loss: 0.6268 - val_accuracy: 0.7192
Epoch 10/100
12271/12271 [==============================] - 259s 21ms/step - loss: 0.5667 - accuracy: 0.7258 - val_loss: 0.6312 - val_accuracy: 0.7201
Epoch 11/100
12271/12271 [==============================] - 245s 20ms/step - loss: 0.5645 - accuracy: 0.7268 - val_loss: 0.6339 - val_accuracy: 0.7166
Epoch 12/100
12271/12271 [==============================] - 244s 20ms/step - loss: 0.5623 - accuracy: 0.7278 - val_loss: 0.6306 - val_accuracy: 0.7135
Epoch 13/100
12271/12271 [==============================] - 244s 20ms/step - loss: 0.5605 - accuracy: 0.7287 - val_loss: 0.6300 - val_accuracy: 0.7171
Epoch 14/100
12271/12271 [==============================] - 242s 20ms/step - loss: 0.5585 - accuracy: 0.7295 - val_loss: 0.6279 - val_accuracy: 0.7133
Epoch 15/100
12271/12271 [==============================] - 244s 20ms/step - loss: 0.5570 - accuracy: 0.7302 - val_loss: 0.6300 - val_accuracy: 0.7119
PS C:\code> 




#=======================================================================================================
batch = 128
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1day30seq38feature_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1day30seq38feature_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 38  # 한 샘플의 특성 수 (레이블 제외)



def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    
    # Position Encoding + Dropout
    x = PositionEncoding()(inputs)
    x = tf.keras.layers.Dropout(0.1)(x)  # 입력 드롭아웃 추가
    
    # Multi-Head Attention + Dropout
    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=64, dropout=0.1)(x, x)
    attn_output = tf.keras.layers.Dropout(0.1)(attn_output)  # 어텐션 출력 드롭아웃 추가
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-8)(attn_output + x)  # 잔차 연결 + 정규화
    
    # Feedforward Network + Dropout
    x_ff1 = tf.keras.layers.Dense(128, activation='tanh')(attn_output2)
    x_ff1 = tf.keras.layers.Dropout(0.3)(x_ff1)  # 피드포워드 드롭아웃 추가
    x_ff2 = tf.keras.layers.Dense(38, activation='tanh')(x_ff1)
    
    # 잔차 연결 + 정규화
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output + x)
    
    # LSTM Layer with Dropout
    lstm_out = tf.keras.layers.LSTM(64, dropout=0.3)(dense_out)
    
    # Output Layer
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)
    
    return tf.keras.models.Model(inputs, output)

    callback path: C:\code\python\autohunting\model\model_checkpoint11.h5
Epoch 1/100
2025-01-05 18:37:46.980175: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2025-01-05 18:37:47.654671: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
12271/12271 [==============================] - 304s 25ms/step - loss: 0.5923 - accuracy: 0.7175 - val_loss: 0.6251 - val_accuracy: 0.7179
Epoch 2/100
12271/12271 [==============================] - 191s 16ms/step - loss: 0.5900 - accuracy: 0.7176 - val_loss: 0.6202 - val_accuracy: 0.7179
Epoch 3/100
12271/12271 [==============================] - 190s 16ms/step - loss: 0.5888 - accuracy: 0.7177 - val_loss: 0.6207 - val_accuracy: 0.7179
Epoch 4/100
12271/12271 [==============================] - 190s 16ms/step - loss: 0.5884 - accuracy: 0.7178 - val_loss: 0.6336 - val_accuracy: 0.7180
Epoch 5/100
12271/12271 [==============================] - 190s 15ms/step - loss: 0.5876 - accuracy: 0.7182 - val_loss: 0.6182 - val_accuracy: 0.7180
Epoch 6/100
12271/12271 [==============================] - 191s 16ms/step - loss: 0.5872 - accuracy: 0.7181 - val_loss: 0.6175 - val_accuracy: 0.7184
Epoch 7/100
12271/12271 [==============================] - 192s 16ms/step - loss: 0.5866 - accuracy: 0.7184 - val_loss: 0.6258 - val_accuracy: 0.7179
Epoch 8/100
12271/12271 [==============================] - 191s 16ms/step - loss: 0.5861 - accuracy: 0.7186 - val_loss: 0.6232 - val_accuracy: 0.7180
Epoch 9/100
12271/12271 [==============================] - 190s 15ms/step - loss: 0.5854 - accuracy: 0.7186 - val_loss: 0.6201 - val_accuracy: 0.7179
Epoch 10/100
12271/12271 [==============================] - 192s 16ms/step - loss: 0.5851 - accuracy: 0.7188 - val_loss: 0.6212 - val_accuracy: 0.7180
Epoch 11/100


#=======================================================================================================
batch = 128
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1day30seq38feature_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1day30seq38feature_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 38  # 한 샘플의 특성 수 (레이블 제외)


def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    x = tf.keras.layers.Dropout(0.1)(x)  # 입력 드롭아웃 추가
    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=64)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-8)(attn_output + x)  # 잔차 연결 + 정규화

    x_ff1 = tf.keras.layers.Dense(128, activation='tanh')(attn_output2)
    x_ff2 = tf.keras.layers.Dense(38, activation='tanh')(x_ff1)
    
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output + x)
    
    lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)
    
    return tf.keras.models.Model(inputs, output)


    callback path: C:\code\python\autohunting\model\model_checkpoin12.h5
    Epoch 1/100
    2025-01-05 19:20:50.106717: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
    2025-01-05 19:20:50.745371: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
    12271/12271 [==============================] - 175s 14ms/step - loss: 0.5917 - accuracy: 0.7174 - val_loss: 0.6248 - val_accuracy: 0.7179
    Epoch 2/100
    12271/12271 [==============================] - 172s 14ms/step - loss: 0.5895 - accuracy: 0.7177 - val_loss: 0.6221 - val_accuracy: 0.7179
    Epoch 3/100
    12271/12271 [==============================] - 181s 15ms/step - loss: 0.5892 - accuracy: 0.7177 - val_loss: 0.6264 - val_accuracy: 0.7177
    Epoch 4/100
    12271/12271 [==============================] - 174s 14ms/step - loss: 0.5887 - accuracy: 0.7179 - val_loss: 0.6383 - val_accuracy: 0.7179
    Epoch 5/100
    12271/12271 [==============================] - 164s 13ms/step - loss: 0.5876 - accuracy: 0.7181 - val_loss: 0.6233 - val_accuracy: 0.7179
    Epoch 6/100
    12271/12271 [==============================] - 166s 14ms/step - loss: 0.5867 - accuracy: 0.7182 - val_loss: 0.6194 - val_accuracy: 0.7179
    Epoch 7/100
    12271/12271 [==============================] - 165s 13ms/step - loss: 0.5864 - accuracy: 0.7183 - val_loss: 0.6272 - val_accuracy: 0.7180
    Epoch 8/100
    12271/12271 [==============================] - 165s 13ms/step - loss: 0.5853 - accuracy: 0.7186 - val_loss: 0.6235 - val_accuracy: 0.7179
    Epoch 9/100
    12271/12271 [==============================] - 159s 13ms/step - loss: 0.5844 - accuracy: 0.7190 - val_loss: 0.6244 - val_accuracy: 0.7179
    Epoch 10/100
    12271/12271 [==============================] - 164s 13ms/step - loss: 0.5834 - accuracy: 0.7193 - val_loss: 0.6240 - val_accuracy: 0.7180
    Epoch 11/100
    12271/12271 [==============================] - 165s 13ms/step - loss: 0.5827 - accuracy: 0.7197 - val_loss: 0.6242 - val_accuracy: 0.7178
    Epoch 12/100
    12271/12271 [==============================] - 166s 14ms/step - loss: 0.5816 - accuracy: 0.7197 - val_loss: 0.6265 - val_accuracy: 0.7177
    Epoch 13/100
    12271/12271 [==============================] - 160s 13ms/step - loss: 0.5809 - accuracy: 0.7200 - val_loss: 0.6303 - val_accuracy: 0.7179
    Epoch 14/100
    12271/12271 [==============================] - 155s 13ms/step - loss: 0.5799 - accuracy: 0.7203 - val_loss: 0.6278 - val_accuracy: 0.7177
    Epoch 15/100















#=======================================================================================================
batch = 128
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1day30seq38feature_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1day30seq38feature_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 38  # 한 샘플의 특성 수 (레이블 제외)

def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=8)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-8)(attn_output1 + x)  # 잔차 연결
    x_ff1 = tf.keras.layers.Dense(128, activation='tanh')(attn_output2) 
    x_ff2 = tf.keras.layers.Dense(38, activation='tanh')(x_ff1) 
    # x_ff3 = tf.keras.layers.Dense(23, activation='tanh')(x_ff2)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    # lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    lstm_out = tf.keras.layers.GlobalAveragePooling1D()(dense_out)
    # lstm_out = tf.keras.layers.GlobalMaxPooling1D()(dense_out)  # 시퀀스 차원을 축소
    # lstm_out = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(dense_out)
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)

    callback path: C:\code\python\autohunting\model\model_checkpoin13.h5
    Epoch 1/100
    2025-01-05 21:37:30.690675: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
    12271/12271 [==============================] - 154s 12ms/step - loss: 0.5927 - accuracy: 0.7175 - val_loss: 0.6308 - val_accuracy: 0.7178
    Epoch 2/100
    12271/12271 [==============================] - 151s 12ms/step - loss: 0.5886 - accuracy: 0.7180 - val_loss: 0.6333 - val_accuracy: 0.7176
    Epoch 3/100
    12271/12271 [==============================] - 148s 12ms/step - loss: 0.5867 - accuracy: 0.7183 - val_loss: 0.6408 - val_accuracy: 0.7182
    Epoch 4/100
    12271/12271 [==============================] - 145s 12ms/step - loss: 0.5849 - accuracy: 0.7184 - val_loss: 0.6439 - val_accuracy: 0.7186
    Epoch 5/100
    12271/12271 [==============================] - 142s 12ms/step - loss: 0.5835 - accuracy: 0.7186 - val_loss: 0.6447 - val_accuracy: 0.7186
    Epoch 6/100
    12271/12271 [==============================] - 143s 12ms/step - loss: 0.5819 - accuracy: 0.7190 - val_loss: 0.6465 - val_accuracy: 0.7185
    Epoch 7/100
    12271/12271 [==============================] - 144s 12ms/step - loss: 0.5805 - accuracy: 0.7192 - val_loss: 0.6480 - val_accuracy: 0.7190
    Epoch 8/100
    12271/12271 [==============================] - 143s 12ms/step - loss: 0.5793 - accuracy: 0.7196 - val_loss: 0.6463 - val_accuracy: 0.7192
    Epoch 9/100
    12271/12271 [==============================] - 144s 12ms/step - loss: 0.5782 - accuracy: 0.7197 - val_loss: 0.6437 - val_accuracy: 0.7193
    Epoch 10/100
    12271/12271 [==============================] - 144s 12ms/step - loss: 0.5771 - accuracy: 0.7200 - val_loss: 0.6390 - val_accuracy: 0.7196
    Epoch 11/100
    12271/12271 [==============================] - 143s 12ms/step - loss: 0.5762 - accuracy: 0.7203 - val_loss: 0.6343 - val_accuracy: 0.7198
#=======================================================================================================
batch = 128
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1day30seq38feature_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1day30seq38feature_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 38  # 한 샘플의 특성 수 (레이블 제외)

def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=8)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-8)(attn_output1 + x)  # 잔차 연결
    x_ff1 = tf.keras.layers.Dense(128, activation='tanh')(attn_output2) 
    x_ff2 = tf.keras.layers.Dense(38, activation='tanh')(x_ff1) 
    # x_ff3 = tf.keras.layers.Dense(23, activation='tanh')(x_ff2)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    # lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    # lstm_out = tf.keras.layers.GlobalAveragePooling1D()(dense_out)
    lstm_out = tf.keras.layers.GlobalMaxPooling1D()(dense_out)  # 시퀀스 차원을 축소
    # lstm_out = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(dense_out)
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)


    callback path: C:\code\python\autohunting\model\model_checkpoin14.h5
    Epoch 1/100
    2025-01-05 22:05:04.378026: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
    12271/12271 [==============================] - 146s 12ms/step - loss: 0.5906 - accuracy: 0.7175 - val_loss: 0.6138 - val_accuracy: 0.7161
    Epoch 2/100
    12271/12271 [==============================] - 144s 12ms/step - loss: 0.5861 - accuracy: 0.7181 - val_loss: 0.6288 - val_accuracy: 0.7177
    Epoch 3/100
    12271/12271 [==============================] - 143s 12ms/step - loss: 0.5831 - accuracy: 0.7187 - val_loss: 0.6287 - val_accuracy: 0.7173
    Epoch 4/100
    12271/12271 [==============================] - 144s 12ms/step - loss: 0.5802 - accuracy: 0.7193 - val_loss: 0.6327 - val_accuracy: 0.7182
    Epoch 5/100
    12271/12271 [==============================] - 134s 11ms/step - loss: 0.5780 - accuracy: 0.7198 - val_loss: 0.6382 - val_accuracy: 0.7176
    Epoch 6/100
    12271/12271 [==============================] - 144s 12ms/step - loss: 0.5761 - accuracy: 0.7206 - val_loss: 0.6332 - val_accuracy: 0.7177
    Epoch 7/100
    12271/12271 [==============================] - 144s 12ms/step - loss: 0.5744 - accuracy: 0.7212 - val_loss: 0.6290 - val_accuracy: 0.7189
    Epoch 8/100
    12271/12271 [==============================] - 146s 12ms/step - loss: 0.5730 - accuracy: 0.7216 - val_loss: 0.6310 - val_accuracy: 0.7188
    Epoch 9/100
    12271/12271 [==============================] - 143s 12ms/step - loss: 0.5717 - accuracy: 0.7222 - val_loss: 0.6214 - val_accuracy: 0.7191
    Epoch 10/100
    12271/12271 [==============================] - 129s 10ms/step - loss: 0.5704 - accuracy: 0.7226 - val_loss: 0.6214 - val_accuracy: 0.7191
    Epoch 11/100
    12271/12271 [==============================] - 133s 11ms/step - loss: 0.5693 - accuracy: 0.7229 - val_loss: 0.6183 - val_accuracy: 0.7199
#=======================================================================================================
batch = 128
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1day30seq38feature_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1day30seq38feature_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 38  # 한 샘플의 특성 수 (레이블 제외)

def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=8)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-8)(attn_output1 + x)  # 잔차 연결
    x_ff1 = tf.keras.layers.Dense(128, activation='tanh')(attn_output2) 
    x_ff2 = tf.keras.layers.Dense(38, activation='tanh')(x_ff1) 
    # x_ff3 = tf.keras.layers.Dense(23, activation='tanh')(x_ff2)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    # lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    # lstm_out = tf.keras.layers.GlobalAveragePooling1D()(dense_out)
    # lstm_out = tf.keras.layers.GlobalMaxPooling1D()(dense_out)  # 시퀀스 차원을 축소
    lstm_out = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(dense_out)
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)
    callback path: C:\code\python\autohunting\model\model_checkpoin15.h5
    Epoch 1/100
    2025-01-05 22:31:32.176119: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
    2025-01-05 22:31:33.599205: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
    12271/12271 [==============================] - 225s 18ms/step - loss: 0.5900 - accuracy: 0.7178 - val_loss: 0.6058 - val_accuracy: 0.7180
    Epoch 2/100
    12271/12271 [==============================] - 217s 18ms/step - loss: 0.5854 - accuracy: 0.7185 - val_loss: 0.6239 - val_accuracy: 0.7179
    Epoch 3/100
    12271/12271 [==============================] - 213s 17ms/step - loss: 0.5821 - accuracy: 0.7193 - val_loss: 0.6096 - val_accuracy: 0.7188
    Epoch 4/100
    12271/12271 [==============================] - 215s 18ms/step - loss: 0.5793 - accuracy: 0.7201 - val_loss: 0.6052 - val_accuracy: 0.7203
    Epoch 5/100
    12271/12271 [==============================] - 218s 18ms/step - loss: 0.5767 - accuracy: 0.7212 - val_loss: 0.6098 - val_accuracy: 0.7210
    Epoch 6/100
    12271/12271 [==============================] - 215s 18ms/step - loss: 0.5743 - accuracy: 0.7221 - val_loss: 0.6149 - val_accuracy: 0.7219
    Epoch 7/100
    12271/12271 [==============================] - 201s 16ms/step - loss: 0.5721 - accuracy: 0.7232 - val_loss: 0.6114 - val_accuracy: 0.7197
    Epoch 8/100
    12271/12271 [==============================] - 209s 17ms/step - loss: 0.5696 - accuracy: 0.7242 - val_loss: 0.6154 - val_accuracy: 0.7216
    Epoch 9/100
    12271/12271 [==============================] - 217s 18ms/step - loss: 0.5671 - accuracy: 0.7252 - val_loss: 0.6164 - val_accuracy: 0.7209
    Epoch 10/100
    12271/12271 [==============================] - 217s 18ms/step - loss: 0.5648 - accuracy: 0.7264 - val_loss: 0.6221 - val_accuracy: 0.7206
    Epoch 11/100
    12271/12271 [==============================] - 216s 18ms/step - loss: 0.5621 - accuracy: 0.7276 - val_loss: 0.6235 - val_accuracy: 0.7180
    Epoch 12/100


#=======================================================================================================
batch = 16
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1day30seq38feature_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1day30seq38feature_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 38  # 한 샘플의 특성 수 (레이블 제외)

def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=8)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-8)(attn_output1 + x)  # 잔차 연결
    x_ff1 = tf.keras.layers.Dense(128, activation='tanh')(attn_output2) 
    x_ff2 = tf.keras.layers.Dense(38, activation='tanh')(x_ff1) 
    # x_ff3 = tf.keras.layers.Dense(23, aqerqqctivation='tanh')(x_ff2)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    # lstm_out = tf.keras.layers.GlobalAveragePooling1D()(dense_out)
    # lstm_out = tf.keras.layers.GlobalMaxPooling1D()(dense_out)  # 시퀀스 차원을 축소
    # lstm_out = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(dense_out)
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)

    callback path: C:\code\python\autohunting\model\model_checkpoin16.h5
    Epoch 1/100
    2025-01-05 23:22:08.234290: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
    2025-01-05 23:22:08.879884: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
    98165/98165 [==============================] - 1102s 11ms/step - loss: 0.5890 - accuracy: 0.7181 - val_loss: 0.6027 - val_accuracy: 0.7192
    Epoch 2/100
    98165/98165 [==============================] - 1128s 11ms/step - loss: 0.5846 - accuracy: 0.7191 - val_loss: 0.6035 - val_accuracy: 0.7185
    Epoch 3/100
    98165/98165 [==============================] - 1120s 11ms/step - loss: 0.5825 - accuracy: 0.7191 - val_loss: 0.6050 - val_accuracy: 0.7154
    Epoch 4/100
    98165/98165 [==============================] - 1123s 11ms/step - loss: 0.5803 - accuracy: 0.7198 - val_loss: 0.6198 - val_accuracy: 0.6806
    Epoch 5/100
    98165/98165 [==============================] - 1118s 11ms/step - loss: 0.5791 - accuracy: 0.7201 - val_loss: 0.6137 - val_accuracy: 0.6845
    Epoch 6/100
    98165/98165 [==============================] - 1114s 11ms/step - loss: 0.5777 - accuracy: 0.7204 - val_loss: 0.6017 - val_accuracy: 0.7163
    Epoch 7/100
    98165/98165 [==============================] - 1119s 11ms/step - loss: 0.5765 - accuracy: 0.7211 - val_loss: 0.6102 - val_accuracy: 0.7116
    Epoch 8/100
    98165/98165 [==============================] - 1128s 11ms/step - loss: 0.5756 - accuracy: 0.7212 - val_loss: 0.6230 - val_accuracy: 0.6886
    Epoch 9/100
    98165/98165 [==============================] - 1116s 11ms/step - loss: 0.5750 - accuracy: 0.7215 - val_loss: 0.6136 - val_accuracy: 0.7019
    Epoch 10/100
    98165/98165 [==============================] - 1125s 11ms/step - loss: 0.5740 - accuracy: 0.7220 - val_loss: 0.6266 - val_accuracy: 0.7088
    Epoch 11/100
    98165/98165 [==============================] - 1128s 11ms/step - loss: 0.5744 - accuracy: 0.7219 - val_loss: 0.6080 - val_accuracy: 0.7127
    Epoch 12/100
    98165/98165 [==============================] - 1118s 11ms/step - loss: 0.5732 - accuracy: 0.7223 - val_loss: 0.6341 - val_accuracy: 0.6868
    Epoch 13/100
    98165/98165 [==============================] - 1123s 11ms/step - loss: 0.5725 - accuracy: 0.7224 - val_loss: 0.6170 - val_accuracy: 0.7025
    Epoch 14/100
    98165/98165 [==============================] - 1122s 11ms/step - loss: 0.5718 - accuracy: 0.7227 - val_loss: 0.6139 - val_accuracy: 0.6944
    Epoch 15/100
    98165/98165 [==============================] - 1113s 11ms/step - loss: 0.5712 - accuracy: 0.7229 - val_loss: 0.6134 - val_accuracy: 0.6981
    Epoch 16/100
    98165/98165 [==============================] - 1118s 11ms/step - loss: 0.5706 - accuracy: 0.7231 - val_loss: 0.6114 - val_accuracy: 0.7065
    Epoch 17/100
    98165/98165 [==============================] - 1115s 11ms/step - loss: 0.5704 - accuracy: 0.7231 - val_loss: 0.5962 - val_accuracy: 0.7121
    Epoch 18/100
    98165/98165 [==============================] - 1136s 12ms/step - loss: 0.5698 - accuracy: 0.7235 - val_loss: 0.6140 - val_accuracy: 0.6919
    Epoch 19/100
    98165/98165 [==============================] - 1128s 11ms/step - loss: 0.5702 - accuracy: 0.7235 - val_loss: 0.6018 - val_accuracy: 0.7151
    Epoch 20/100
    98165/98165 [==============================] - 1123s 11ms/step - loss: 0.5694 - accuracy: 0.7236 - val_loss: 0.6047 - val_accuracy: 0.7102
    Epoch 21/100
    98165/98165 [==============================] - 1131s 12ms/step - loss: 0.5696 - accuracy: 0.7235 - val_loss: 0.6281 - val_accuracy: 0.6983
    Epoch 22/100
    98165/98165 [==============================] - 1097s 11ms/step - loss: 0.5695 - accuracy: 0.7234 - val_loss: 0.5937 - val_accuracy: 0.7167
    Epoch 23/100
    98165/98165 [==============================] - 1121s 11ms/step - loss: 0.5690 - accuracy: 0.7238 - val_loss: 0.6107 - val_accuracy: 0.6909
    Epoch 24/100
    98165/98165 [==============================] - 1129s 12ms/step - loss: 0.5687 - accuracy: 0.7238 - val_loss: 0.6158 - val_accuracy: 0.6970
    Epoch 25/100
    98165/98165 [==============================] - 1102s 11ms/step - loss: 0.5688 - accuracy: 0.7236 - val_loss: 0.6074 - val_accuracy: 0.7075
    Epoch 26/100
    98165/98165 [==============================] - 1121s 11ms/step - loss: 0.5691 - accuracy: 0.7236 - val_loss: 0.6167 - val_accuracy: 0.7011
    Epoch 27/100
    98165/98165 [==============================] - 1126s 11ms/step - loss: 0.5695 - accuracy: 0.7231 - val_loss: 0.6037 - val_accuracy: 0.7038
    Epoch 28/100
    98165/98165 [==============================] - 1104s 11ms/step - loss: 0.5686 - accuracy: 0.7235 - val_loss: 0.6001 - val_accuracy: 0.7179
    Epoch 29/100
    98165/98165 [==============================] - 1099s 11ms/step - loss: 0.5682 - accuracy: 0.7239 - val_loss: 0.6099 - val_accuracy: 0.7100
    Epoch 30/100
    98165/98165 [==============================] - 1119s 11ms/step - loss: 0.5691 - accuracy: 0.7234 - val_loss: 0.6047 - val_accuracy: 0.7046
    Epoch 31/100
    98165/98165 [==============================] - 1084s 11ms/step - loss: 0.5686 - accuracy: 0.7236 - val_loss: 0.6136 - val_accuracy: 0.7183
    Epoch 32/100


#=======================================================================================================
batch = 32
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1day30seq38feature_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1day30seq38feature_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 38  # 한 샘플의 특성 수 (레이블 제외)

def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=64, num_heads=8)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-8)(attn_output1 + x)  # 잔차 연결
    x_ff1 = tf.keras.layers.Dense(128, activation='tanh')(attn_output2) 
    x_ff2 = tf.keras.layers.Dense(38, activation='tanh')(x_ff1) 
    # x_ff3 = tf.keras.layers.Dense(23, aqerqqctivation='tanh')(x_ff2)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    # lstm_out = tf.keras.layers.GlobalAveragePooling1D()(dense_out)
    # lstm_out = tf.keras.layers.GlobalMaxPooling1D()(dense_out)  # 시퀀스 차원을 축소
    # lstm_out = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(dense_out)
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)

    callback path: C:\code\python\autohunting\model\model_checkpoin17.h5
Epoch 1/100
2025-01-06 09:03:36.983803: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2025-01-06 09:03:38.353217: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
49083/49083 [==============================] - 587s 12ms/step - loss: 0.5896 - accuracy: 0.7177 - val_loss: 0.6077 - val_accuracy: 0.7181
Epoch 2/100
49083/49083 [==============================] - 565s 12ms/step - loss: 0.5845 - accuracy: 0.7185 - val_loss: 0.6046 - val_accuracy: 0.7181
Epoch 3/100
49083/49083 [==============================] - 567s 12ms/step - loss: 0.5807 - accuracy: 0.7195 - val_loss: 0.5977 - val_accuracy: 0.7192
Epoch 4/100
49083/49083 [==============================] - 573s 12ms/step - loss: 0.5779 - accuracy: 0.7204 - val_loss: 0.6070 - val_accuracy: 0.7183
Epoch 5/100
49083/49083 [==============================] - 581s 12ms/step - loss: 0.5751 - accuracy: 0.7214 - val_loss: 0.6079 - val_accuracy: 0.7171
Epoch 6/100
49083/49083 [==============================] - 555s 11ms/step - loss: 0.5726 - accuracy: 0.7221 - val_loss: 0.6026 - val_accuracy: 0.7202
Epoch 7/100
49083/49083 [==============================] - 576s 12ms/step - loss: 0.5706 - accuracy: 0.7228 - val_loss: 0.6108 - val_accuracy: 0.7203
Epoch 8/100
49083/49083 [==============================] - 582s 12ms/step - loss: 0.5680 - accuracy: 0.7238 - val_loss: 0.6053 - val_accuracy: 0.7163
Epoch 9/100
49083/49083 [==============================] - 572s 12ms/step - loss: 0.5662 - accuracy: 0.7243 - val_loss: 0.6041 - val_accuracy: 0.7182
Epoch 10/100
49083/49083 [==============================] - 583s 12ms/step - loss: 0.5645 - accuracy: 0.7249 - val_loss: 0.6023 - val_accuracy: 0.7205
Epoch 11/100
49083/49083 [==============================] - 581s 12ms/step - loss: 0.5638 - accuracy: 0.7254 - val_loss: 0.6090 - val_accuracy: 0.7161
Epoch 12/100
49083/49083 [==============================] - 576s 12ms/step - loss: 0.5615 - accuracy: 0.7265 - val_loss: 0.5956 - val_accuracy: 0.7204
Epoch 13/100
49083/49083 [==============================] - 556s 11ms/step - loss: 0.5602 - accuracy: 0.7271 - val_loss: 0.6028 - val_accuracy: 0.7196
Epoch 14/100
49083/49083 [==============================] - 562s 11ms/step - loss: 0.5590 - accuracy: 0.7275 - val_loss: 0.6149 - val_accuracy: 0.7197
Epoch 15/100
49083/49083 [==============================] - 578s 12ms/step - loss: 0.5575 - accuracy: 0.7282 - val_loss: 0.6117 - val_accuracy: 0.7138
Epoch 16/100
49083/49083 [==============================] - 578s 12ms/step - loss: 0.5561 - accuracy: 0.7290 - val_loss: 0.6192 - val_accuracy: 0.7119
Epoch 17/100


callback path: C:\code\python\autohunting\model\model_checkpoin17.h5
Epoch 1/100
2025-01-06 11:45:32.707372: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2025-01-06 11:45:34.293592: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101
49083/49083 [==============================] - 1074s 22ms/step - loss: 0.5869 - accuracy: 0.7182 - val_loss: 0.6281 - val_accuracy: 0.6676
Epoch 2/100
49083/49083 [==============================] - 1051s 21ms/step - loss: 0.5803 - accuracy: 0.7195 - val_loss: 0.6069 - val_accuracy: 0.6980
Epoch 3/100
49083/49083 [==============================] - 1053s 21ms/step - loss: 0.5770 - accuracy: 0.7207 - val_loss: 0.6045 - val_accuracy: 0.7048
Epoch 4/100
49083/49083 [==============================] - 945s 19ms/step - loss: 0.5741 - accuracy: 0.7215 - val_loss: 0.6183 - val_accuracy: 0.7094
Epoch 5/100
49083/49083 [==============================] - 822s 17ms/step - loss: 0.5721 - accuracy: 0.7221 - val_loss: 0.6041 - val_accuracy: 0.7177
Epoch 6/100
49083/49083 [==============================] - 1102s 22ms/step - loss: 0.5687 - accuracy: 0.7237 - val_loss: 0.6272 - val_accuracy: 0.6781
Epoch 7/100
49083/49083 [==============================] - 978s 20ms/step - loss: 0.5664 - accuracy: 0.7248 - val_loss: 0.6205 - val_accuracy: 0.7068
Epoch 8/100

#=======================================================================================================
batch = 128
lr = 0.001
output_dir = r'C:\code\python\autohunting\dataset_TFRecord'
train_tfrecord_filename = '1day30seq38feature_TRAIN.tfrecord'   -> Standardization
val_tfrecord_filename = '1day30seq38feature_VAL.tfrecord'
sequence_length = 30  # 시퀀스 길이
feature_dim = 38  # 한 샘플의 특성 수 (레이블 제외)

def transformer_lstm_model(input_shape):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = PositionEncoding()(inputs)
    attn_output1 = tf.keras.layers.MultiHeadAttention(key_dim=128, num_heads=16)(x, x)
    attn_output2 = tf.keras.layers.LayerNormalization(epsilon=1e-8)(attn_output1 + x)  # 잔차 연결
    x_ff1 = tf.keras.layers.Dense(256, activation='tanh')(attn_output2) 
    x_ff2 = tf.keras.layers.Dense(38, activation='tanh')(x_ff1) 
    # x_ff3 = tf.keras.layers.Dense(23, activation='tanh')(x_ff2)
    dense_out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x_ff2 + attn_output1 + x)  # 잔차 연결
    # lstm_out = tf.keras.layers.LSTM(64)(dense_out)
    # lstm_out = tf.keras.layers.GlobalAveragePooling1D()(dense_out)
    # lstm_out = tf.keras.layers.GlobalMaxPooling1D()(dense_out)  # 시퀀스 차원을 축소
    lstm_out = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128))(dense_out)
    output = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_out)

    return tf.keras.models.Model(inputs, output)
