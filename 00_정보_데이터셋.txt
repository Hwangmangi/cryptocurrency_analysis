●1. tf.data



======================================================================================================================
●1. tf.data

TensorFlow에서 데이터셋을 다루는 것은 효율적이고 빠르게 모델을 훈련하기 위해 매우 중요합니다. 
TensorFlow 2.x에서는 특히 tf.data API를 사용하여 데이터를 처리하는 방법이 많이 사용됩니다. 
이는 대규모 데이터를 메모리 효율적으로 로드하고, 전처리하고, 모델에 공급하는데 최적화되어 있습니다.

1)tf.data를 사용하는 이유
    -대규모 데이터 처리: 메모리에 전부 적재할 수 없는 데이터도 효율적으로 로드 가능.
    -데이터 증강 및 전처리: 데이터 로드 시 동적으로 변형 가능.
    -병렬 처리: 데이터 로드 및 전처리를 병렬로 수행하여 훈련 시간을 단축.
    -Batching & Prefetching: 미리 데이터를 로드하여 훈련이 중단 없이 이루어지도록 보장.

2)tf.data.Dataset의 병렬 처리 및 비동기적 데이터 공급 방식
    TensorFlow의 tf.data API는 병렬 처리와 비동기 데이터 로드를 통해 모델 훈련을 가속화합니다. 
    이를 위해 내부적으로 **스레드와 큐(queue)**를 사용하여 데이터를 동적으로 생성하고, fit() 함수에서 필요할 때마다 데이터를 가져와 사용할 수 있도록 설계되었습니다.

    1. Prefetch를 통한 비동기 처리
        dataset.prefetch(buffer_size=tf.data.AUTOTUNE)는 fit() 함수가 훈련을 진행하는 동안 다음 배치 데이터를 미리 가져오는 비동기 작업을 수행합니다.
        이 작업은 별도의 스레드에서 이루어지기 때문에, 모델이 훈련 중일 때도 데이터 로드가 동시에 진행됩니다.
        AUTOTUNE 옵션을 사용하면 TensorFlow가 자동으로 최적의 buffer_size를 결정하여 성능을 최적화합니다.
    
    2. 병렬 데이터 로드 및 변환
        dataset.map()에서 num_parallel_calls=tf.data.AUTOTUNE 옵션을 사용하면, 데이터를 여러 스레드에서 병렬로 전처리할 수 있습니다.
        예를 들어, 이미지 데이터에 대한 증강이나 정규화 작업이 여러 스레드에서 동시에 처리되기 때문에 데이터 로드와 변환 속도가 크게 향상됩니다.